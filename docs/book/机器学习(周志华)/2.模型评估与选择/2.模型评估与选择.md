# 2. 模型评估与选择

## 2.1经验误差与过拟合

`通常将分类错误的样本数占样本总数的比例称为“错误率”`，即`如果在m个样本中有a个样本分类错误`，则`错误率`为`a/m`；相应的，`1-a/m`称为`精度`，即`精度=1-错误率`。

更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异，称为“误差”，学习器在训练集上的误差称为`“训练误差”或“经验误差”`，在新样本上的误差称为`“泛化误差”`。

我们实际希望的是“泛化误差”更小的学习器，为了达到这个目的，应该从训练样本中尽可能学出适用于所有潜在样本的“普通规律”。当学习器把训练样本学得“太好”的时候，很可能已经`把训练样本自身的一些特点当做了潜在样本都会具有的一般性质，这样就会导致泛化能力下降`。这种现象在机器学习中称作`“过拟合”`。与`“过拟合”`相对的是`“欠拟合”`，这是指`对训练样本的一般性质未学好`。

![](2.1.png)

过拟合是机器学习面临的关键障碍，而且过拟合是无法避免的，只能缓解，或者说减少其风险。关于这一点，可大致这样理解：

`机器学习面临的问题通常是NP难甚至更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获最优解，这就意味着我们构造性地证明了“P=NP”；因此，只要相信“P≠NP”，过拟合就不可避面。`

如果想要理解上面这句话可以阅读以下[如下链接](https://zhuanlan.zhihu.com/p/143003261)中的文章。

现实生活中，有多种学习算法可供选择，甚至对于同一个算法，如果参数不同，产生的模型会出现很大差异。因此就存在了“模型选择问题”。

理想的解决方案是对候选模型的泛化误差进行评估，然后选择泛化误差最小的模型，但上面已经提过，我们无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，因此需要一些特殊的评估方法。

## 2.2 评估方法

